/*
PUS SERVICE 12 : ON-BOARD MONITORING
*/

import service_libraries.pus_services.pus_service12.pus_service12_help;


interface PUSS12Iface {
    procedure exec_tc (&mut self, tc_handler : &mut TCHandlerT, action_status: &mut Status<i32>);
    procedure do_monitoring (&mut self, PMONID: u16, evID : &mut u16, fault_info : &mut FaultInfo, event_triggered: &mut bool);
    procedure is_PMON_enabled(&mut self, PMONID : usize, is_enabled : &mut bool);
};



resource class PUSService12 provides PUSS12Iface {

    do_monitoring_req_status : DoMonitoringReqStatus;
    do_monitoring_req_status_update : DoMonitoringReqStatusUpdate;

    exec_tc_req_status : PSExecTCReqStatus;
    exec_tc_req_status_update : PS12ExecTCReqStatusUpdate;

    param_mon_config_table : [ParamMonitoringConfiguration; max_num_pmon_ids];
    monitoring_transition_counter : u8; 
    param_mon_transitions_table : [ParamMonitoringTransition; max_num_transitions];

    system_data_pool_u32 : access AtomicArrayAccess<u32; sdp_num_u32_params>;
    system_data_pool_u8 : access AtomicArrayAccess<u8; sdp_num_u8_params>;

    tm_channel : access TMChannelIface;
    a_tm_handler_pool : access Allocator<TMHandlerT>;
    tm_counter : access TMCounterIface;

    pus_service_9 : access PUSS9Iface;


    viewer is_valid_PMONID(&self) -> bool{

        var is_valid : bool = false;

        if (self->do_monitoring_req_status_update.PMONID as usize < max_num_pmon_ids) {

            is_valid = true;
        }

        return is_valid;
    }

    viewer is_limits_monitoring(&self) -> bool{

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 
        var is_limits_mon : bool = false;

        if (self->param_mon_config_table[current_PMON_ID].type is MonitorCheckType::Limits) {

            is_limits_mon = true;
        }

        return is_limits_mon;
    }


    viewer is_expected_value_monitoring(&self) -> bool{

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 
        var is_exp_val_mon : bool = false;

        if (self->param_mon_config_table[current_PMON_ID].type is MonitorCheckType::ExpectedValue){

            is_exp_val_mon = true;
        }

        return is_exp_val_mon;
    }

    viewer get_limits_monitoring_definition(&self) -> ParamLimitCheckDefinition {

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 
        var monitoring_definition : ParamLimitCheckDefinition = {
            low_limit = 0,
            low_limit_evID = 0,
            high_limit = 0,
            high_limit_evID = 0
        };

        match(self->param_mon_config_table[current_PMON_ID].definition) {

            case ParamLimitCheck(limit_check_def)=> {

                monitoring_definition = limit_check_def;
            }
            
            case _ => {
                //error
            }
        }

        return monitoring_definition;
    }


    viewer get_expected_value_monitoring_definition(&self) -> ParamValueCheckDefinition {

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 
        var monitoring_definition : ParamValueCheckDefinition = {
            mask_value = 0,
            expected_value = 0,
            EvID = 0
        };

        match(self->param_mon_config_table[current_PMON_ID].definition) {

            case ParamValueCheck(param_check_definition)=> {

                monitoring_definition = param_check_definition;
                
            }
            case _ =>{

            }
            
        }

        return monitoring_definition;
    }

    method manage_interval_control(&priv self)->DoMonitoringReqStatus{

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 
        var next_status : DoMonitoringReqStatus = DoMonitoringReqStatus::Exit;

        self->param_mon_config_table[current_PMON_ID].interval_control = self->param_mon_config_table[current_PMON_ID].interval_control + 1;

        if(self->param_mon_config_table[current_PMON_ID].interval_control >= self->param_mon_config_table[current_PMON_ID].interval){

            self->param_mon_config_table[current_PMON_ID].interval_control = 0;
            next_status = DoMonitoringReqStatus::GetMonitoringType;

        } else {

            next_status = DoMonitoringReqStatus::Exit;
        }

        return next_status;
    }

    viewer check_PID_status_limits_monitoring(&self)-> CheckLimitsStatus{

        var current_monitor_definition : ParamLimitCheckDefinition = self->get_limits_monitoring_definition();
        var check_status: CheckLimitsStatus = CheckLimitsStatus::MonitorUnchecked;

        if(self->PID_is_above_upper_limit(&current_monitor_definition)){

            check_status = CheckLimitsStatus::MonitorAboveHighLimit;

        }
        else if(self->PID_is_below_lower_limit(&current_monitor_definition)){

            check_status = CheckLimitsStatus::MonitorBelowLowLimit;

        }
        else {

            //monitor within limits
            check_status = CheckLimitsStatus::MonitorWithinLimits;
        }

        return check_status;

    }

    viewer check_PID_status_exp_val_monitoring(&self)-> CheckValueStatus {

        var current_monitor_definition : ParamValueCheckDefinition = self->get_expected_value_monitoring_definition();
        var check_status : CheckValueStatus = CheckValueStatus::MonitorUnchecked;

        if(self->PID_has_expected_masked_value(&current_monitor_definition)){

            check_status = CheckValueStatus::MonitorValueExpected;

        }
        else {

            check_status = CheckValueStatus::MonitorValueUnexpected;

        }

        return check_status;
    }



    viewer PID_is_above_upper_limit(&self, limit_check_def : &ParamLimitCheckDefinition) -> bool {

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 
        var res : bool = false;
        var upper_limit : u32 = limit_check_def->high_limit;
        var PID : u16 = self->param_mon_config_table[current_PMON_ID].PID;
        var type : DataPoolItemType = sys_data_pool_get_item_type(PID);
        var SDP_value : u32 = 0;

        match type {

            case u32_t => {
                self->system_data_pool_u32.load_index((PID as usize - sdp_first_u32_param_id), &mut SDP_value);
            }
            case u8_t => {
                var SDP_value_u8 : u8 = 0;
                self->system_data_pool_u8.load_index((PID as usize - sdp_first_u8_param_id), &mut SDP_value_u8);
                SDP_value = SDP_value_u8 as u32;
            }
            case NoValidPID => {
               //Error
            }
        }
        
        if (SDP_value > upper_limit) {

            res = true;
        }

        return res;
    }


   viewer PID_is_below_lower_limit(&self, limit_check_def : &ParamLimitCheckDefinition) -> bool {

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 
        var res : bool = false;
        var lower_limit : u32 = limit_check_def->low_limit;
        var PID : u16 = self->param_mon_config_table[current_PMON_ID].PID;
        var type : DataPoolItemType = sys_data_pool_get_item_type(PID);
        var SDP_value : u32 = 0;

        match type {

            case u32_t => {
                self->system_data_pool_u32.load_index((PID as usize - sdp_first_u32_param_id), &mut SDP_value);
            }
            case u8_t => {
                var SDP_value_u8 : u8 = 0;
                self->system_data_pool_u8.load_index(PID as usize - sdp_first_u8_param_id, &mut SDP_value_u8);
                SDP_value = SDP_value_u8 as u32;
            }
            case NoValidPID => {
               //Error
            }
        }
        
        if (SDP_value < lower_limit) {

            res = true;
        }

        return res;
    }

    
    viewer PID_has_expected_masked_value(&self, expected_value_check_definition : &ParamValueCheckDefinition) -> bool {

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize;
        var res : bool = false;
        var PID : u16 = self->param_mon_config_table[current_PMON_ID].PID;
        var SDP_value : u32 = 0;
        var type : DataPoolItemType = sys_data_pool_get_item_type(PID);

        match type {

            case u32_t => {
                self->system_data_pool_u32.load_index((PID as usize - sdp_first_u32_param_id), &mut SDP_value);
            }
            case u8_t => {
                var SDP_value_u8 : u8 = 0;
                self->system_data_pool_u8.load_index((PID as usize - sdp_first_u8_param_id), &mut SDP_value_u8);
                SDP_value = SDP_value_u8 as u32;
            }
            case NoValidPID => {
               //Error
            }
        }

        if ((SDP_value & expected_value_check_definition->mask_value) == (expected_value_check_definition->expected_value & expected_value_check_definition->mask_value)) {

            res = true;
        }

        return res;
    }


    method manage_unexpected_value (&priv self) -> DoMonitoringReqStatus {

        var next_status : DoMonitoringReqStatus = DoMonitoringReqStatus::GetRequestStatusUpdate;

        var fault_info : ParamFaultValueInfo = {PID = 0,
                                                PID_value = 0,
                                                PID_mask = 0,
                                                PID_expected_value = 0};

        let check_status : CheckValueStatus = CheckValueStatus::MonitorValueUnexpected;
        self->do_monitoring_req_status_update.new_status = CheckState::ParamValueStatus(check_status);
        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 

        match(self->param_mon_config_table[current_PMON_ID].definition){

            case ParamValueCheck(check_definition) => {

                fault_info.PID = self->param_mon_config_table[current_PMON_ID].PID; 
                fault_info.PID_expected_value = check_definition.expected_value;
                fault_info.PID_mask = check_definition.mask_value;

                var type : DataPoolItemType = sys_data_pool_get_item_type(fault_info.PID);

                match type {

                    case u32_t => {
                        self->system_data_pool_u32.load_index((fault_info.PID as usize - sdp_first_u32_param_id), &mut (fault_info.PID_value));
                    }
                    case u8_t => {
                        var value : u8 = 0;
                        self->system_data_pool_u8.load_index((fault_info.PID as usize - sdp_first_u8_param_id), &mut value);
                        fault_info.PID_value = value as u32;
                        
                    }
                    case NoValidPID => {
                        next_status = DoMonitoringReqStatus::Exit;
                    }
                }

                if(self->manage_new_status()){

                    self->do_monitoring_req_status_update.event_triggered = true;
                    self->do_monitoring_req_status_update.fault_info = FaultInfo::ParamFaultValue(fault_info);
                    self->add_monitoring_transition();
                    self->do_monitoring_req_status_update.EvID = check_definition.EvID;
                }

            }
            case _ => {
                next_status = DoMonitoringReqStatus::Exit;
            }
        }

        return next_status;
    }


    method manage_expected_value (&priv self) -> DoMonitoringReqStatus {

        var next_status : DoMonitoringReqStatus = DoMonitoringReqStatus::GetRequestStatusUpdate;

        let check_status : CheckValueStatus = CheckValueStatus::MonitorValueExpected;
        self->do_monitoring_req_status_update.new_status = CheckState::ParamValueStatus(check_status); 

        if(self->manage_new_status()){

            self->add_monitoring_transition();

        }
        return next_status;
    }



    method manage_param_above_upper_limit (&priv self) -> DoMonitoringReqStatus {

        var next_status : DoMonitoringReqStatus = DoMonitoringReqStatus::GetRequestStatusUpdate;

        var fault_info : ParamOutOfLimitInfo = {PID = 0,
                                                PID_value = 0,
                                                PID_limit = 0};

        let check_status : CheckLimitsStatus = CheckLimitsStatus:: MonitorAboveHighLimit;
        self->do_monitoring_req_status_update.new_status = CheckState::ParamLimitStatus(check_status);

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 

        match(self->param_mon_config_table[current_PMON_ID].definition){

            case ParamLimitCheck(check_definition) => {

                fault_info.PID = self->param_mon_config_table[current_PMON_ID].PID; 
                fault_info.PID_limit = check_definition.high_limit;

                var type : DataPoolItemType = sys_data_pool_get_item_type(fault_info.PID);

                match type {

                    case u32_t => {
                        self->system_data_pool_u32.load_index((fault_info.PID as usize - sdp_first_u32_param_id), &mut (fault_info.PID_value));
                    }
                    case u8_t => {
                        var value : u8 = 0;
                        self->system_data_pool_u8.load_index((fault_info.PID as usize - sdp_first_u8_param_id), &mut value);
                        fault_info.PID_value = value as u32;
                    }
                    case NoValidPID => {
                        next_status = DoMonitoringReqStatus::Exit;
                    }
                }

                if(self->manage_new_status()){

                    self->do_monitoring_req_status_update.event_triggered = true;
                    self->do_monitoring_req_status_update.fault_info = FaultInfo::ParamOutOfLimit(fault_info);
                    self->add_monitoring_transition();
                    self->do_monitoring_req_status_update.EvID = check_definition.high_limit_evID;
                }

            }
            case _ => {
                next_status = DoMonitoringReqStatus::Exit;

            }
        }

        return next_status;
    }


    method manage_param_below_lower_limit (&priv self) -> DoMonitoringReqStatus {

        var next_status : DoMonitoringReqStatus = DoMonitoringReqStatus::GetRequestStatusUpdate;

        var fault_info : ParamOutOfLimitInfo = {PID = 0,
                                                PID_value = 0,
                                                PID_limit = 0};

        let check_status : CheckLimitsStatus = CheckLimitsStatus:: MonitorBelowLowLimit;
        self->do_monitoring_req_status_update.new_status = CheckState::ParamLimitStatus(check_status);

        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize; 

        match(self->param_mon_config_table[current_PMON_ID].definition){

            case ParamLimitCheck(check_definition) => {

                fault_info.PID = self->param_mon_config_table[current_PMON_ID].PID; 
                fault_info.PID_limit = check_definition.low_limit;

                var type : DataPoolItemType = sys_data_pool_get_item_type(fault_info.PID);

                match type {

                    case u32_t => {
                        self->system_data_pool_u32.load_index((fault_info.PID as usize - sdp_first_u32_param_id), &mut (fault_info.PID_value));
                    }
                    case u8_t => {
                        var value : u8 = 0;
                        self->system_data_pool_u8.load_index((fault_info.PID as usize - sdp_first_u8_param_id), &mut value);
                        fault_info.PID_value = value as u32;
                    }
                    case NoValidPID => {
                        next_status = DoMonitoringReqStatus::Exit;
                    }
                }

                if(self->manage_new_status()){

                    self->do_monitoring_req_status_update.event_triggered = true;
                    self->do_monitoring_req_status_update.fault_info = FaultInfo::ParamOutOfLimit(fault_info);
                    self->add_monitoring_transition();
                    self->do_monitoring_req_status_update.EvID = check_definition.low_limit_evID;
                }

            }
            case _ => {
                next_status = DoMonitoringReqStatus::Exit;
            }
        }

        return next_status;
    }

    method manage_param_within_limits (&priv self) -> DoMonitoringReqStatus{

        var next_status : DoMonitoringReqStatus = DoMonitoringReqStatus::GetRequestStatusUpdate;

        var within_limits : CheckLimitsStatus = CheckLimitsStatus::MonitorWithinLimits;
        var new_status : CheckState = CheckState::ParamLimitStatus(within_limits);
        self->do_monitoring_req_status_update.new_status = new_status;
        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize;
        let current_status : CheckState = self->param_mon_config_table[current_PMON_ID].current_state;

        if(self->are_status_equal(new_status, current_status) == false){

            if(self->manage_new_status()){

                self->add_monitoring_transition();
            }
        }

        return next_status;
    }

    viewer are_status_equal(&self, status1: CheckState, status2: CheckState)->bool{

        var equal : bool = get_check_status_index(status1) == get_check_status_index(status2);
        return equal;
    }


    method manage_new_status(&priv self)->bool{

        var transition: bool = false;
        let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize;

        var new_state : CheckState = self->do_monitoring_req_status_update.new_status;
        var current_state : CheckState = self->param_mon_config_table[current_PMON_ID].current_state;
        var temp_state : CheckState = self->param_mon_config_table[current_PMON_ID].temp_state;

        if (self->are_status_equal(new_state, current_state) == false) {

            if(are_status_equal(new_state, temp_state)) {

                self->param_mon_config_table[current_PMON_ID].repetition_control = self->param_mon_config_table[current_PMON_ID].repetition_control + 1;

            } else {

                self->param_mon_config_table[current_PMON_ID].temp_state = new_state;
                self->param_mon_config_table[current_PMON_ID].repetition_control = 1;
                var current_obt : MissionObt = {seconds = 0, finetime = 0};
                self->pus_service_9.get_current_obt(&mut current_obt);
                self->param_mon_config_table[current_PMON_ID].transition_obt = current_obt;
            }

            if (self->param_mon_config_table[current_PMON_ID].repetition_control >= self->param_mon_config_table[current_PMON_ID].repetition) {

                self->param_mon_config_table[current_PMON_ID].repetition_control = 0;
                self->param_mon_config_table[current_PMON_ID].current_state = new_state;
                transition = true;

            }
        } 
        else {
            
            self->param_mon_config_table[current_PMON_ID].temp_state = new_state;
            self->param_mon_config_table[current_PMON_ID].repetition_control = 0;

        }

        return transition;
        
    }

    viewer build_tm_12_12(&self, p_tm_handler : &mut TMHandlerT, tm_seq_counter : u16, status : &mut Status<i32>) {

        startup_tm(p_tm_handler);
        append_u8_appdata_field(p_tm_handler, self->monitoring_transition_counter, status);

        for i : usize in 0 .. max_num_transitions while (i < (self->monitoring_transition_counter as usize)) {

            var aux_prev_status : u8 = 0;
            var aux_new_status : u8 = 0;

            append_u16_appdata_field(p_tm_handler, self->param_mon_transitions_table[i].PMONID, status);
            append_u16_appdata_field(p_tm_handler, self->param_mon_transitions_table[i].PID, status);
            var type_id : u8 = get_type_index(self->param_mon_transitions_table[i].type);
            append_u8_appdata_field(p_tm_handler, type_id, status);
            
            
            if(self->param_mon_transitions_table[i].type is MonitorCheckType::ExpectedValue){
                append_u32_appdata_field(p_tm_handler, self->param_mon_transitions_table[i].mask_value, status);
            }

            aux_prev_status = get_check_status_index(self->param_mon_transitions_table[i].prev_status);
            aux_new_status = get_check_status_index(self->param_mon_transitions_table[i].new_status);

            append_u32_appdata_field(p_tm_handler, self->param_mon_transitions_table[i].new_value, status);
            append_u32_appdata_field(p_tm_handler, self->param_mon_transitions_table[i].limit_value, status);
            append_u8_appdata_field(p_tm_handler, aux_prev_status, status);
            append_u8_appdata_field(p_tm_handler, aux_new_status, status);
            append_u32_appdata_field(p_tm_handler, self->param_mon_transitions_table[i].trans_obt.seconds, status); 
        }
        if(*status is Success){
            var current_obt : MissionObt = {seconds = 0, finetime = 0};
            self->pus_service_9.get_current_obt(&mut current_obt);
            close_tm(p_tm_handler, 12, 12, tm_seq_counter, current_obt);
        }


        return;
    }


    method add_monitoring_transition(&priv self){

        var monitoring_status : Status<i32> = Success;

        if((self->monitoring_transition_counter as usize) < max_num_transitions){

            let current_PMON_ID : usize = (self->do_monitoring_req_status_update.PMONID) as usize;

            self->param_mon_transitions_table[self->monitoring_transition_counter as usize].PID = self->param_mon_config_table[current_PMON_ID].PID;
            self->param_mon_transitions_table[self->monitoring_transition_counter as usize].PMONID = self->do_monitoring_req_status_update.PMONID;
            self->param_mon_transitions_table[self->monitoring_transition_counter as usize].type = self->param_mon_config_table[current_PMON_ID].type;
            match self->do_monitoring_req_status_update.fault_info {
                case ParamOutOfLimit(out_of_limit_info)=> {
                    self->param_mon_transitions_table[self->monitoring_transition_counter as usize].limit_value = out_of_limit_info.PID_limit;
                    self->param_mon_transitions_table[self->monitoring_transition_counter as usize].new_value = out_of_limit_info.PID_value;
                }
                case ParamFaultValue(fault_value_info)=> {
                    self->param_mon_transitions_table[self->monitoring_transition_counter as usize].limit_value = fault_value_info.PID_expected_value;
                    self->param_mon_transitions_table[self->monitoring_transition_counter as usize].new_value = fault_value_info.PID_value;

                }
                case Empty => {
                    //error
                }
            }
             
            match (self->param_mon_config_table[current_PMON_ID].definition) {
                case ParamValueCheck(value_definition)=> {

                     self->param_mon_transitions_table[self->monitoring_transition_counter as usize].mask_value = value_definition.mask_value;

                }
                case _ => {

                }

            }

            self->param_mon_transitions_table[self->monitoring_transition_counter as usize].new_status = self->do_monitoring_req_status_update.new_status;
            self->param_mon_transitions_table[self->monitoring_transition_counter as usize].prev_status = self->param_mon_config_table[current_PMON_ID].current_state;
            self->param_mon_transitions_table[self->monitoring_transition_counter as usize].trans_obt = self->param_mon_config_table[current_PMON_ID].transition_obt;

            self->monitoring_transition_counter = self->monitoring_transition_counter + 1;
        }

        if(self->monitoring_transition_counter as usize == max_num_transitions){

            var tm_handler : Option<box TMHandlerT> = None;
            self->a_tm_handler_pool.alloc(&mut tm_handler);

            match tm_handler {

                case Some(b_tm_handler) => {

                    var tm_count : u16 = 0 : u16;
                    self->tm_counter.get_next_tm_count(&mut tm_count);

                    self->build_tm_12_12(&mut b_tm_handler, tm_count, &mut monitoring_status);
                    //Enviar telemetría a través del TM_CHANNEL
                    if( monitoring_status is Success) {
                        self->tm_channel.send_tm(b_tm_handler, &mut monitoring_status);

                    } else {
                        //Generar TM[5,2]
                        self->a_tm_handler_pool.free(b_tm_handler);
                    }
                
            
                }
                case None => {
                    monitoring_status = Failure(TM_POOL_ALLOC_FAILURE);

                }
            } 

            
            self->monitoring_transition_counter = 0;
        }

        return;
    }

    procedure do_monitoring (&mut self, PMONID: u16, evID : &mut u16, fault_info : &mut FaultInfo, event_triggered: &mut bool) {

        for i : usize in 0 .. 4 while (self->do_monitoring_req_status is DoMonitoringReqStatus::Exit == false){
            match self->do_monitoring_req_status {
                case Init=> {

                    self->do_monitoring_req_status_update.PMONID = PMONID;
                    self->do_monitoring_req_status_update.EvID = *evID;
                    self->do_monitoring_req_status_update.fault_info = *fault_info;
                    self->do_monitoring_req_status = DoMonitoringReqStatus::CheckPMONID;
                    self->do_monitoring_req_status_update.event_triggered = false;

                }
                case CheckPMONID => {

                    //choice point
                    if (self->is_valid_PMONID()) {
                        self->do_monitoring_req_status = self->manage_interval_control(); //method 
                    } else {
                        self->do_monitoring_req_status = DoMonitoringReqStatus::Exit;
                    }
                }
                
                case GetMonitoringType => {

                    if(self->param_mon_config_table[PMONID as usize].enabled == true){

                        //choice point
                        if(self->is_limits_monitoring()) {

                            self->do_monitoring_req_status = DoMonitoringReqStatus::DoLimitsMonitoring;
                            

                        } else if (self->is_expected_value_monitoring()) {

                            self->do_monitoring_req_status = DoMonitoringReqStatus::DoExpectedValueMonitoring;

                        }
                        else {
                            self->do_monitoring_req_status = DoMonitoringReqStatus::Exit;
                        }

                    } else {

                        self->do_monitoring_req_status = DoMonitoringReqStatus::Exit;
                    }
                
                } 
                case DoLimitsMonitoring =>{

                    var limits_monitoring_status : CheckLimitsStatus = self->check_PID_status_limits_monitoring(); 

                    match limits_monitoring_status {
                        case MonitorAboveHighLimit => {

                            self->do_monitoring_req_status = self->manage_param_above_upper_limit(); //method
                        }
                        case MonitorBelowLowLimit => {

                            self->do_monitoring_req_status = self->manage_param_below_lower_limit(); //method

                        }
                        case MonitorWithinLimits => {

                            self->do_monitoring_req_status = self->manage_param_within_limits(); //method
                        }
                        case MonitorUnchecked => {

                        }

                    }
                        
                }
                case DoExpectedValueMonitoring => {

                    var exp_value_monitoring_status: CheckValueStatus = self->check_PID_status_exp_val_monitoring(); //viewer

                    match exp_value_monitoring_status {
                        case MonitorValueUnexpected =>{
                            self->do_monitoring_req_status = self->manage_unexpected_value(); //method
                        }
                        case MonitorValueExpected =>{

                            self->do_monitoring_req_status = self->manage_expected_value(); //method

                        }
                        case MonitorUnchecked => {

                        }
                        

                    }
                }
                case GetRequestStatusUpdate => {
                    *evID = self->do_monitoring_req_status_update.EvID;
                    *fault_info = self->do_monitoring_req_status_update.fault_info;
                    *event_triggered = self->do_monitoring_req_status_update.event_triggered;
                }
                case Exit => {
                    //error
                }
            }
        }

        if(self->do_monitoring_req_status is DoMonitoringReqStatus::Exit){

            self->do_monitoring_req_status = DoMonitoringReqStatus::Init;
        }

        return;
    }

    procedure is_PMON_enabled(&mut self, PMONID : usize, is_enabled : &mut bool) {

        if (PMONID < max_num_pmon_ids) {

            if(self->param_mon_config_table[PMONID].type is MonitorCheckType::Free == false){

                *is_enabled = self->param_mon_config_table[PMONID as usize].enabled;
            }
        }

        return;
    }


    viewer get_PMON_type (&self, PMONID : usize) -> MonitorCheckType {

        var mon_type : MonitorCheckType = MonitorCheckType::Free;

        if (PMONID < max_num_pmon_ids) {

            mon_type = self->param_mon_config_table[PMONID as usize].type;
        }

        return mon_type;
    }

    method set_unchecked (&priv self) {

        var valid_PMONID : usize = (self->exec_tc_req_status_update. tc_data_1_2_6.PMONID) as usize;

        match (self->param_mon_config_table[valid_PMONID].type) {

            case ExpectedValue => {
                var monitor_unchecked : CheckValueStatus = CheckValueStatus::MonitorUnchecked;
                self->param_mon_config_table[valid_PMONID].current_state = CheckState::ParamValueStatus(monitor_unchecked);
            }
            case Limits => {
                var monitor_unchecked : CheckLimitsStatus = CheckLimitsStatus::MonitorUnchecked;
                self->param_mon_config_table[valid_PMONID].current_state = CheckState::ParamLimitStatus(monitor_unchecked);
            }
            case Delta => {
                var monitor_unchecked : CheckDeltaStatus = CheckDeltaStatus::MonitorUnchecked;
                self->param_mon_config_table[valid_PMONID].current_state = CheckState::ParamDeltaStatus(monitor_unchecked);
            }
            case Free => {
                //Do nothing
            }
        }

        self->param_mon_config_table[valid_PMONID].temp_state = self->param_mon_config_table[valid_PMONID].current_state;

        return;
    }

    method exec12_1TC(&priv self) -> PSExecTCReqStatus {

        var ack_enabled : bool = false;
        var next_status : PSExecTCReqStatus = {exec_tc_status = PSReqStatus::Exit, status = Success};

        var current_obt : MissionObt = {seconds = 0, finetime = 0};

        var tm_handler : Option<box TMHandlerT> = None;
        self->a_tm_handler_pool.alloc(&mut tm_handler);

        match tm_handler {

            case Some(b_tm_handler) => {

                var tm_count : u16 = 0 : u16;
                self->tm_counter.get_next_tm_count(&mut tm_count);

                if (self->exec_tc_req_status_update.tc_data_1_2_6.N != 1) {

                    self->pus_service_9.get_current_obt(&mut current_obt);
                    build_tm_1_4_num_of_instr_not_valid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                     self->exec_tc_req_status_update.tc_data_1_2_6.N, current_obt, &mut next_status.status);

                    if (next_status.status is Success){

                        self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                    } 
                    else {
                        self->a_tm_handler_pool.free(b_tm_handler);
                        
                    }
                   
                }
                else {

                    var PMONID : usize = (self->exec_tc_req_status_update.tc_data_1_2_6.PMONID) as usize;
                    var is_valid_PMONID : bool = PMONID < max_num_pmon_ids;

                    if (is_valid_PMONID) {

                        if(self->param_mon_config_table[PMONID as usize].type is MonitorCheckType::Free == false){

                            self->pus_service_9.get_current_obt(&mut current_obt);
                            build_tm_1_3(&mut b_tm_handler, tm_count, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                            if (ack_enabled) {

                                if (next_status.status is Success){

                                    self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                                }
                                else {
                                    self->a_tm_handler_pool.free(b_tm_handler);
                                }

                            }
                            else {
                                        
                                self->a_tm_handler_pool.free(b_tm_handler);
                            }
                            
                            self->param_mon_config_table[PMONID as usize].enabled = true;
                            self->param_mon_config_table[PMONID as usize].interval_control = 0;
                            self->param_mon_config_table[PMONID as usize].repetition_control = 0;

                            var tm_handler2 : Option<box TMHandlerT> = None;
                            self->a_tm_handler_pool.alloc(&mut tm_handler2);

                            match tm_handler2 {

                                case Some(b_tm_handler2) => {

                                    var tm_count2 : u16 = 0 : u16;
                                    self->tm_counter.get_next_tm_count(&mut tm_count2);
                                    self->pus_service_9.get_current_obt(&mut current_obt);
                                    build_tm_1_7(&mut b_tm_handler2, tm_count2, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                                    if (ack_enabled) {

                                        if (next_status.status is Success){

                                            self->tm_channel.send_tm(b_tm_handler2, &mut next_status.status);

                                        }
                                        else {
                                            self->a_tm_handler_pool.free(b_tm_handler2);
                                           
                                        }

                                    }
                                    else {
                                        
                                        self->a_tm_handler_pool.free(b_tm_handler2);
                                    }
                                    
                                }
                                case None => {
                                    next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
                                }
                            }

                        } else {

                            self->pus_service_9.get_current_obt(&mut current_obt);
                            build_tm_1_4_PMON_undefined(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                         self->exec_tc_req_status_update. tc_data_1_2_6.PMONID, current_obt, &mut next_status.status);

                            if (next_status.status is Success){

                                self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                            } 
                            else {
                               
                                self->a_tm_handler_pool.free(b_tm_handler);
                            } 
                        }
                    } else {

                        self->pus_service_9.get_current_obt(&mut current_obt);
                        build_tm_1_4_PMONID_invalid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                             self->exec_tc_req_status_update. tc_data_1_2_6.PMONID, current_obt, &mut next_status.status);

                        if (next_status.status is Success){

                            self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                        } 
                        else {
                           
                            self->a_tm_handler_pool.free(b_tm_handler);
                        }
                    }
                }
                    
            }
            case None => {
                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
            }
        }

        return next_status;
    }


    method exec12_2TC(&priv self) -> PSExecTCReqStatus {

        var ack_enabled : bool = false;
        var next_status : PSExecTCReqStatus = {exec_tc_status = PSReqStatus::Exit, status = Success};

        var current_obt : MissionObt = {seconds = 0, finetime = 0};
        
        var tm_handler : Option<box TMHandlerT> = None;
        self->a_tm_handler_pool.alloc(&mut tm_handler);

        match tm_handler {

            case Some(b_tm_handler) => {

                var tm_count : u16 = 0 : u16;
                self->tm_counter.get_next_tm_count(&mut tm_count);

                if (self->exec_tc_req_status_update.tc_data_1_2_6.N != 1) {

                    self->pus_service_9.get_current_obt(&mut current_obt);
                    build_tm_1_4_num_of_instr_not_valid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                     self->exec_tc_req_status_update.tc_data_1_2_6.N, current_obt, &mut next_status.status);

                    if (next_status.status is Success){

                        self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                    } 
                    else {
                       
                        self->a_tm_handler_pool.free(b_tm_handler);
                    }
                  
                }
                else {

                    var is_valid_PMONID : bool = (self->exec_tc_req_status_update.tc_data_1_2_6.PMONID) as usize < max_num_pmon_ids;

                    if (is_valid_PMONID) {

                        if(self->param_mon_config_table[(self->exec_tc_req_status_update.tc_data_1_2_6.PMONID) as usize].type is MonitorCheckType::Free == false){

                            self->pus_service_9.get_current_obt(&mut current_obt);
                            build_tm_1_3(&mut b_tm_handler, tm_count, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                            if (ack_enabled) {

                                if (next_status.status is Success){

                                    self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                                }
                                else {
                                    self->a_tm_handler_pool.free(b_tm_handler);
            
                                }

                            } else {
     
                                self->a_tm_handler_pool.free(b_tm_handler); 
                            }
                            
                            self->param_mon_config_table[(self->exec_tc_req_status_update.tc_data_1_2_6.PMONID) as usize].enabled = false;
                            self->set_unchecked();
                            var tm_handler2 : Option<box TMHandlerT> = None;
                            self->a_tm_handler_pool.alloc(&mut tm_handler2);

                            match tm_handler2 {

                                case Some(b_tm_handler2) => {

                                    var tm_count2 : u16 = 0 : u16;
                                    self->tm_counter.get_next_tm_count(&mut tm_count2);
                                    self->pus_service_9.get_current_obt(&mut current_obt);
                                    build_tm_1_7(&mut b_tm_handler2, tm_count2, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                                    if (ack_enabled) {

                                        if (next_status.status is Success){

                                            self->tm_channel.send_tm(b_tm_handler2, &mut next_status.status);

                                        }
                                        else {
                                            self->a_tm_handler_pool.free(b_tm_handler2);
                                           
                                        }

                                    } else {
                                        
                                        self->a_tm_handler_pool.free(b_tm_handler2);
                                    }
                                }
                                case None => {
                                    next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
                                }
                            }

                        } else {

                            self->pus_service_9.get_current_obt(&mut current_obt);
                            build_tm_1_4_PMON_undefined(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                             self->exec_tc_req_status_update. tc_data_1_2_6.PMONID, current_obt, &mut next_status.status);

                            if (next_status.status is Success){

                                self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                            } 
                            else {
                             
                                self->a_tm_handler_pool.free(b_tm_handler);
                            }
                        }
                    } else {

                        self->pus_service_9.get_current_obt(&mut current_obt);
                        build_tm_1_4_PMONID_invalid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                     self->exec_tc_req_status_update. tc_data_1_2_6.PMONID, current_obt, &mut next_status.status);

                        if (next_status.status is Success){

                            self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                        } 
                        else {
                            
                            self->a_tm_handler_pool.free(b_tm_handler);
                    
                        }
                        
                    }
                }
                
            }
            case None => {
                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
            }
        }

        return next_status;
    }

    method add_valid_mng_mon_def (&priv self){

        let PMONID : usize = (self->exec_tc_req_status_update.tc_data_5.mon_config.PID) as usize;

        (self->param_mon_config_table)[PMONID] = self->exec_tc_req_status_update.tc_data_5.mon_config;

        (self->param_mon_config_table)[PMONID].enabled = false;

        //set unckecked
        if (PMONID < max_num_pmon_ids){

            match (self->param_mon_config_table[PMONID].type) {

                case ExpectedValue => {

                    var status : CheckValueStatus = CheckValueStatus::MonitorUnchecked;
                    (self->param_mon_config_table)[PMONID].current_state = CheckState::ParamValueStatus(status);
                }
                case Limits => {

                    var status : CheckLimitsStatus = CheckLimitsStatus::MonitorUnchecked;
                    (self->param_mon_config_table)[PMONID].current_state = CheckState::ParamLimitStatus(status);

                }
                case Delta => { 

                    var status : CheckDeltaStatus = CheckDeltaStatus::MonitorUnchecked;
                    (self->param_mon_config_table)[PMONID].current_state = CheckState::ParamDeltaStatus(status);

                }
                case Free => {

                    //Error

                }    
    
            }

        }

        return;
    }

    method exec12_5TC(&priv self) -> PSExecTCReqStatus{

        var ack_enabled : bool = false;
        var next_status : PSExecTCReqStatus = {exec_tc_status = PSReqStatus::Exit, status = Success};

        var current_obt : MissionObt = {seconds = 0, finetime = 0};

        var tm_handler : Option<box TMHandlerT> = None;
        self->a_tm_handler_pool.alloc(&mut tm_handler);

         match tm_handler {

            case Some(b_tm_handler) => {

                var tm_count : u16 = 0 : u16;
                self->tm_counter.get_next_tm_count(&mut tm_count);

                if (self->exec_tc_req_status_update.tc_data_5.N != 1) {

                    self->pus_service_9.get_current_obt(&mut current_obt);
                    build_tm_1_4_num_of_instr_not_valid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                 self->exec_tc_req_status_update.tc_data_5.N, current_obt, &mut next_status.status);

                    if (next_status.status is Success){

                        self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                    } 
                    else {
                     
                        self->a_tm_handler_pool.free(b_tm_handler);
                
                    }
                    
                } else if (sys_data_pool_is_valid_PID(self->exec_tc_req_status_update.tc_data_5.mon_config.PID) == false) {

                    self->pus_service_9.get_current_obt(&mut current_obt);
                    build_tm_1_4_PID_not_valid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                 self->exec_tc_req_status_update.tc_data_5.mon_config.PID, current_obt, &mut next_status.status);

                    if (next_status.status is Success){

                        self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                    } 
                    else {
                     
                        self->a_tm_handler_pool.free(b_tm_handler);
                     
                    }
                    
                } else if (self->exec_tc_req_status_update.tc_data_5.mon_config.type is MonitorCheckType::Limits) {

                    if(is_valid_check_limit_def(&self->exec_tc_req_status_update.tc_data_5.mon_config.definition)){

                        self->pus_service_9.get_current_obt(&mut current_obt);
                        build_tm_1_3(&mut b_tm_handler, tm_count, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                        if (ack_enabled) {

                            if (next_status.status is Success){

                                self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                            }
                            else {
                                self->a_tm_handler_pool.free(b_tm_handler);
                        
                            }

                        } 
                        else {
                            
                            self->a_tm_handler_pool.free(b_tm_handler);
                        }
                        
                        self->add_valid_mng_mon_def();
            
                        var tm_handler2 : Option<box TMHandlerT> = None;
                        self->a_tm_handler_pool.alloc(&mut tm_handler2);

                        match tm_handler2 {

                            case Some(b_tm_handler2) => {

                                var tm_count2 : u16 = 0 : u16;
                                self->tm_counter.get_next_tm_count(&mut tm_count2);
                                self->pus_service_9.get_current_obt(&mut current_obt);
                                build_tm_1_7(&mut b_tm_handler2, tm_count2, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                                if (ack_enabled) {

                                    if (next_status.status is Success){

                                        self->tm_channel.send_tm(b_tm_handler2, &mut next_status.status);

                                    }
                                    else {
                                        self->a_tm_handler_pool.free(b_tm_handler2);
                                       
                                    }

                                } else {
                                    
                                    self->a_tm_handler_pool.free(b_tm_handler2);
                                }
                            }
                            case None => {
                                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
                            }
                        
                        }
                    } else {

                        self->pus_service_9.get_current_obt(&mut current_obt);
                        build_tm_1_4_PMON_definition_invalid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                         (self->exec_tc_req_status_update.tc_data_5.PMONID), current_obt, &mut next_status.status);

                        if (next_status.status is Success){

                            self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                        } 
                        else {

                            self->a_tm_handler_pool.free(b_tm_handler);
                
                        }  
                    }

                } else if (self->exec_tc_req_status_update.tc_data_5.mon_config.type is MonitorCheckType::ExpectedValue) {

                    self->pus_service_9.get_current_obt(&mut current_obt);
                    build_tm_1_3(&mut b_tm_handler, tm_count, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                    if (ack_enabled) {

                        if (next_status.status is Success){

                            self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                        }
                        else {
                            self->a_tm_handler_pool.free(b_tm_handler);
                
                        }

                    } else {
                        
                        self->a_tm_handler_pool.free(b_tm_handler);
                    }
                    
                    self->add_valid_mng_mon_def();

                    var tm_handler2 : Option<box TMHandlerT> = None;
                    self->a_tm_handler_pool.alloc(&mut tm_handler2);

                    match tm_handler2 {

                        case Some(b_tm_handler2) => {

                            var tm_count2 : u16 = 0 : u16;
                            self->tm_counter.get_next_tm_count(&mut tm_count2);
                            self->pus_service_9.get_current_obt(&mut current_obt);
                            build_tm_1_7(&mut b_tm_handler2, tm_count2, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                            if (ack_enabled) {

                                if (next_status.status is Success){

                                    self->tm_channel.send_tm(b_tm_handler2, &mut next_status.status);

                                }
                                else {
                                    self->a_tm_handler_pool.free(b_tm_handler2);
            
                                }

                            } else {
                                
                                self->a_tm_handler_pool.free(b_tm_handler2);
                            }
                           
                        }
                        case None => {
                            next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
                        }
                    }
                } else {

                    self->pus_service_9.get_current_obt(&mut current_obt);
                    build_tm_1_4_PMON_definition_invalid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                 (self->exec_tc_req_status_update.tc_data_5.PMONID), current_obt, &mut next_status.status);

                    if (next_status.status is Success){

                        self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                    } 
                    else {
                       
                        self->a_tm_handler_pool.free(b_tm_handler);
                    }
                }
            }
            case None => {
                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
            }
        }

        return next_status;

    }

//Comprobar exec12_6TC enteramente
    method exec12_6TC(&priv self) -> PSExecTCReqStatus {

        var ack_enabled : bool = false;
        var next_status : PSExecTCReqStatus = {exec_tc_status = PSReqStatus::Exit, status = Success};

        var current_obt : MissionObt = {seconds = 0, finetime = 0};

        var tm_handler : Option<box TMHandlerT> = None;
        self->a_tm_handler_pool.alloc(&mut tm_handler);


         match tm_handler {

            case Some(b_tm_handler) => {

                var tm_count : u16 = 0 : u16;
                self->tm_counter.get_next_tm_count(&mut tm_count);

                if (self->exec_tc_req_status_update.tc_data_1_2_6.N != 1) {

                    self->pus_service_9.get_current_obt(&mut current_obt);
                    build_tm_1_4_num_of_instr_not_valid(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                     self->exec_tc_req_status_update.tc_data_1_2_6.N, current_obt, &mut next_status.status);

                    if (next_status.status is Success){

                        self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                    } 
                    else {
                     
                        self->a_tm_handler_pool.free(b_tm_handler);
                    }
                 
                }
                else {
                    
                    var PMON_type : MonitorCheckType = get_check_type((self->exec_tc_req_status_update.tc_data_1_2_6.PMONID) as u8);

                    if(PMON_type is MonitorCheckType::Free){

                        self->pus_service_9.get_current_obt(&mut current_obt);
                        build_tm_1_4_PMON_undefined(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                     self->exec_tc_req_status_update.tc_data_1_2_6.PMONID, current_obt, &mut next_status.status);

                        if (next_status.status is Success){

                            self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                        } 
                        else {
                           
                            self->a_tm_handler_pool.free(b_tm_handler);
                        }


                    } else if (self->param_mon_config_table[(self->exec_tc_req_status_update.tc_data_1_2_6.PMONID)as usize].enabled == false){ 

                        self->pus_service_9.get_current_obt(&mut current_obt);
                        build_tm_1_3(&mut b_tm_handler, tm_count, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);
                        
                        if (ack_enabled) {

                            if (next_status.status is Success){

                                self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                            }
                            else {
                                self->a_tm_handler_pool.free(b_tm_handler);
                              
                            }

                        } else {
                            
                            self->a_tm_handler_pool.free(b_tm_handler);
                        }
                      
                        self->param_mon_config_table[(self->exec_tc_req_status_update.tc_data_1_2_6.PMONID) as usize].type = MonitorCheckType::Free;

                        var tm_handler2 : Option<box TMHandlerT> = None;
                        self->a_tm_handler_pool.alloc(&mut tm_handler2);

                        match tm_handler2 {

                            case Some(b_tm_handler2) => {

                                var tm_count2 : u16 = 0 : u16;
                                self->tm_counter.get_next_tm_count(&mut tm_count2);
                                self->pus_service_9.get_current_obt(&mut current_obt);
                                build_tm_1_7(&mut b_tm_handler2, tm_count2, self->exec_tc_req_status_update.flags_ack, current_obt, &mut next_status.status, &mut ack_enabled);

                                if (ack_enabled) {

                                    if (next_status.status is Success){

                                        self->tm_channel.send_tm(b_tm_handler2, &mut next_status.status);

                                    }
                                    else {
                                        self->a_tm_handler_pool.free(b_tm_handler2);
                    
                                    }

                                } else {
                                    
                                    self->a_tm_handler_pool.free(b_tm_handler2);
                                }
                    
                            }
                            case None => {
                                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
                            }
                        }
                    } else {

                        self->pus_service_9.get_current_obt(&mut current_obt);
                        build_tm_1_4_PMON_enabled(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                         self->exec_tc_req_status_update.tc_data_1_2_6.PMONID, current_obt, &mut next_status.status);

                        if (next_status.status is Success){

                            self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                        } 
                        else {
                          
                            self->a_tm_handler_pool.free(b_tm_handler);
        
                        }

                    }

                }


            } case None => {

                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
            }
        }

        return next_status;

    }


    viewer get_PMON_limit_check_definition (&self, tc_handler : &mut TCHandlerT, status: &mut Status<i32>) -> MonitorDefinition {

        var limits_def : ParamLimitCheckDefinition = {
            low_limit = 0,
            low_limit_evID = 0,
            high_limit = 0,
            high_limit_evID = 0
        };

        var type : DataPoolItemType = sys_data_pool_get_item_type(self->exec_tc_req_status_update.tc_data_5.mon_config.PID);

        match type {

            case u8_t => {

                var low_limit : u8 = 0;
                var high_limit : u8 = 0;

                //get low limit
                *status = tc_handler_get_u8_appdata_field(tc_handler, &mut low_limit);

                //get low limit evID
                *status = tc_handler_get_u16_appdata_field(tc_handler, &mut (limits_def.low_limit_evID));

                //get high limit
                *status = tc_handler_get_u8_appdata_field(tc_handler, &mut high_limit);

                //get high limit evID
                *status = tc_handler_get_u16_appdata_field(tc_handler, &mut (limits_def.high_limit_evID));

                limits_def.low_limit = low_limit as u32;
                limits_def.high_limit = high_limit as u32;

            }
            case u32_t => {

                //get low limit
                *status = tc_handler_get_u32_appdata_field(tc_handler, &mut (limits_def.low_limit));
                
                //get low limit evID
                *status = tc_handler_get_u16_appdata_field(tc_handler, &mut (limits_def.low_limit_evID));

                //get high limit
                *status = tc_handler_get_u32_appdata_field(tc_handler, &mut (limits_def.low_limit));

                //get high limit evID
                *status = tc_handler_get_u16_appdata_field(tc_handler, &mut (limits_def.high_limit_evID));

            }
            case NoValidPID => {
                *status = Failure(INVALID_PID_ERROR);
            }


        }

        var param_limit_check_definition : MonitorDefinition = MonitorDefinition::ParamLimitCheck(limits_def);
        
        return param_limit_check_definition;

    }


    viewer get_PMON_value_check_definition (&self, tc_handler : &mut TCHandlerT, status : &mut Status<i32>) -> MonitorDefinition {

        var value_def : ParamValueCheckDefinition = {
            mask_value = 0,
            expected_value = 0,
            EvID = 0
        };

        var type : DataPoolItemType = sys_data_pool_get_item_type(self->exec_tc_req_status_update.tc_data_5.mon_config.PID);

        match type {

            case u8_t => {

                var mask : u8 = 0;
                var expected_value : u8 = 0;

                //get mask
                *status = tc_handler_get_u8_appdata_field(tc_handler, &mut mask);

                //get expected value
                *status = tc_handler_get_u8_appdata_field(tc_handler, &mut expected_value);

                //get EvID
                *status = tc_handler_get_u16_appdata_field(tc_handler, &mut (value_def.EvID));

                value_def.mask_value = mask as u32;
                value_def.expected_value = expected_value as u32;

            }
            case u32_t => {

                //get mask
                *status = tc_handler_get_u32_appdata_field(tc_handler, &mut (value_def.mask_value));

                //get expected value
                *status = tc_handler_get_u32_appdata_field(tc_handler, &mut (value_def.expected_value));

                //get EvID
                *status = tc_handler_get_u16_appdata_field(tc_handler, &mut (value_def.EvID));

            }
            case NoValidPID => {
                *status = Failure(INVALID_PID_ERROR);
            }

        }

        var expected_value_check_definition : MonitorDefinition = MonitorDefinition::ParamValueCheck(value_def);
        return expected_value_check_definition;

    }


    viewer manage_short_pack_length_error(&self) -> PSExecTCReqStatus {

        var next_status : PSExecTCReqStatus = {exec_tc_status = PSReqStatus::Exit, status = Success};

        var current_obt : MissionObt = {seconds = 0, finetime = 0};

        var tm_handler : Option<box TMHandlerT> = None;
        self->a_tm_handler_pool.alloc(&mut tm_handler);

        match tm_handler {

            case Some(b_tm_handler) => {

                var tm_count : u16 = 0 : u16;
                self->tm_counter.get_next_tm_count(&mut tm_count);
                self->pus_service_9.get_current_obt(&mut current_obt);
                build_tm_1_4_short_pack_length(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                             (self->exec_tc_req_status_update.tc_num_bytes), current_obt, &mut next_status.status);

                if (next_status.status is Success){

                    self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                } 
                else {
        
                    self->a_tm_handler_pool.free(b_tm_handler);
                    
                }
            }
            case None => {
                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
            }
        }

        return next_status;
    }

    viewer manage_error_in_acceptance(&self) -> PSExecTCReqStatus {

        var next_status : PSExecTCReqStatus = {exec_tc_status = PSReqStatus::Exit, status = Success};

        var current_obt : MissionObt = {seconds = 0, finetime = 0};

        var tm_handler : Option<box TMHandlerT> = None;
        self->a_tm_handler_pool.alloc(&mut tm_handler);

        match tm_handler {

            case Some(b_tm_handler) => {

                var tm_count : u16 = 0 : u16;
                self->tm_counter.get_next_tm_count(&mut tm_count);

                self->pus_service_9.get_current_obt(&mut current_obt);
                build_tm_1_4_error_in_acceptance(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                 current_obt, &mut next_status.status);
                
                if (next_status.status is Success){

                    self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                } 
                else {
                    self->a_tm_handler_pool.free(b_tm_handler);
                
                }
                
            }
            case None => {
                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
            }
        }

        return next_status;
    }

    viewer manage_tm_limit_app_data_reached(&self) -> PSExecTCReqStatus {

        var next_status : PSExecTCReqStatus = {exec_tc_status = PSReqStatus::Exit, status = Success};

        var current_obt : MissionObt = {seconds = 0, finetime = 0};

        var tm_handler : Option<box TMHandlerT> = None;
        self->a_tm_handler_pool.alloc(&mut tm_handler);

        match tm_handler {

            case Some(b_tm_handler) => {

                var tm_count : u16 = 0 : u16;
                self->tm_counter.get_next_tm_count(&mut tm_count);

                self->pus_service_9.get_current_obt(&mut current_obt);
                build_tm_1_8_tm_exceed_limit_appdata(&mut b_tm_handler, tm_count, (self->exec_tc_req_status_update.packet_id), (self->exec_tc_req_status_update.packet_error_ctrl),
                                 current_obt, &mut next_status.status);
                
                if (next_status.status is Success){

                    self->tm_channel.send_tm(b_tm_handler, &mut next_status.status);

                } 
                else {
                    self->a_tm_handler_pool.free(b_tm_handler);

                }
                
            }
            case None => {
                next_status.status = Failure(TM_POOL_ALLOC_FAILURE);
            }
        }

        return next_status;
    }


    procedure exec_tc (&mut self, tc_handler : &mut TCHandlerT, action_status: &mut Status<i32>){

        var subtype : u8 = tc_handler->df_header.subtype;

        for i : usize in 0 .. 3 while (self->exec_tc_req_status.exec_tc_status is PSReqStatus::Exit == false) {

            match self->exec_tc_req_status.exec_tc_status {

                case Init => {

                    self->exec_tc_req_status_update.packet_id = tc_handler->packet_header.packet_id;
                    self->exec_tc_req_status_update.packet_error_ctrl = tc_handler->packet_error_ctrl;
                    self->exec_tc_req_status_update.flags_ack = tc_handler->df_header.flag_ver_ack;
                    self->exec_tc_req_status_update.tc_num_bytes = tc_handler->tc_descriptor.tc_num_bytes;

                    if (subtype == 1 || subtype == 2 || subtype == 6){
                    
                        self->exec_tc_req_status.status = tc_handler_get_u8_appdata_field(tc_handler, &mut (self->exec_tc_req_status_update.tc_data_1_2_6.N));
                        self->exec_tc_req_status.status  = tc_handler_get_u16_appdata_field(tc_handler, &mut (self->exec_tc_req_status_update.tc_data_1_2_6.PMONID));

                    } else if (subtype == 5){

                        var aux : u8 = 0;

                        self->exec_tc_req_status.status = tc_handler_get_u8_appdata_field(tc_handler, &mut (self->exec_tc_req_status_update.tc_data_5.N));
                        self->exec_tc_req_status.status = tc_handler_get_u16_appdata_field(tc_handler, &mut (self->exec_tc_req_status_update.tc_data_5.PMONID));
                        self->exec_tc_req_status.status = tc_handler_get_u16_appdata_field(tc_handler, &mut (self->exec_tc_req_status_update.tc_data_5.mon_config.PID));
                        self->exec_tc_req_status.status = tc_handler_get_u8_appdata_field(tc_handler, &mut (self->exec_tc_req_status_update.tc_data_5.mon_config.interval));
                        self->exec_tc_req_status.status = tc_handler_get_u8_appdata_field(tc_handler, &mut (self->exec_tc_req_status_update.tc_data_5.mon_config.repetition));
                        self->exec_tc_req_status.status = tc_handler_get_u8_appdata_field(tc_handler, &mut aux);
                        self->exec_tc_req_status_update.tc_data_5.mon_config.type = get_check_type(aux);

                        if (self->exec_tc_req_status_update.tc_data_5.mon_config.type is MonitorCheckType::ExpectedValue) {

                           //TO DO: Esto no puede ser así, estoy pasando una referencia mutable de un campo del recurso a un viewer
                           self->exec_tc_req_status_update.tc_data_5.mon_config.definition = self->get_PMON_value_check_definition(tc_handler, &mut self->exec_tc_req_status.status);

                        }
                        else if (self->exec_tc_req_status_update.tc_data_5.mon_config.type is MonitorCheckType::Limits){

                            //TO DO: Esto no puede ser así, estoy pasando una referencia mutable de un campo del recurso a un viewer
                            self->exec_tc_req_status_update.tc_data_5.mon_config.definition = self->get_PMON_limit_check_definition(tc_handler, &mut self->exec_tc_req_status.status);
                        }
                        else {
                            //Error
                        }


                    } else {

                        // Invalid subtype

                    }

                    if (self->exec_tc_req_status.status is Success) {

                        self->exec_tc_req_status.exec_tc_status = PSReqStatus::ExecTC;
                        
                    } else {

                        self->exec_tc_req_status.exec_tc_status = PSReqStatus::Exit;
                        
                    }

                }
                case ExecTC => {

                    if (subtype == 1) {

                        self->exec_tc_req_status = self->exec12_1TC();

                    } else if (subtype == 2) {

                        self->exec_tc_req_status = self->exec12_2TC();

                    } else if (subtype == 5) {

                        self->exec_tc_req_status = self->exec12_5TC();

                    } else if (subtype == 6) {

                        self->exec_tc_req_status = self->exec12_6TC();

                    } else {
 
                        self->exec_tc_req_status.status = Failure(ACCEPTANCE_ERROR);
                        self->exec_tc_req_status.exec_tc_status = PSReqStatus::Exit;
                    }
                }
                case Exit => {
                    //Unreachable point
                }  
            }
        }

        match self->exec_tc_req_status.status {
                        
            case Success => {

                *action_status = Success;
    
            }
            case Failure(error_code) => {

                if (error_code == ACCEPTANCE_ERROR) {

                    self->exec_tc_req_status = self->manage_error_in_acceptance();
                    
                } else if (error_code == BUILD_TM_ERROR) {

                    self->exec_tc_req_status = self->manage_tm_limit_app_data_reached();
                
                } else if (error_code == TC_DATA_OUT_OF_RANGE_ERROR) {

                    self->exec_tc_req_status = self->manage_short_pack_length_error();

                } else if (error_code == INVALID_PID_ERROR) {

                    // TO DO: Manage Invalid PID Error   
                
                } else {
                    
                    *action_status = Failure(error_code);
                
                }
                
            }  
        }

        self->exec_tc_req_status = {
                    exec_tc_status = PSReqStatus::Init,
                    status = Success
                };

        return;
    
    }

     
};




